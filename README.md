DataSpark: Illuminating Insights for Global Electronics

Project Overview:
DataSpark is a comprehensive data analytics initiative aimed at unlocking valuable insights for Global Electronics, a leading consumer electronics retailer. By leveraging advanced data analysis and visualization techniques, this project drives actionable recommendations to optimize operations, improve customer satisfaction, and fuel business growth.

Key Skills:
Data Cleaning & Preprocessing
Exploratory Data Analysis (EDA)
Python
SQL for Data Management
Power BI for Visualization

Industry Domain
Retail Analytics (Electronics Industry)

Objectives:
Global Electronics provided datasets related to their customers, products, sales, stores, and currency exchange rates. The analysis focuses on:

Customer Insights: Segmenting customers for better marketing
Sales Performance: Identifying trends and top-performing products
Store Operations: Improving store performance based on sales data
Currency Impact: Understanding exchange rate effects on sales

Approach:
Data Cleaning: Handle missing values, correct data types, and merge datasets for analysis.
SQL Database: Insert cleaned data into MySQL and create tables.
Dashboards: Build interactive Power BI dashboards connected to SQL.
SQL Queries: Execute key SQL queries to derive insights.

Key Insights:
Customer Analysis: Analyze demographics, purchasing behavior, and segmentation.
Sales Analysis: Track overall performance, sales by product/store, and the effect of exchange rates.
Product & Store Analysis: Identify popular products, profitable categories, and store performance based on size and region.

Deliverables:
Clean Data: Integrated datasets for analysis.
Dashboards: Interactive visualizations in Power BI.
Recommendations: Actionable insights to improve marketing, inventory, sales, and store management.

Tools Used
Python: For data cleaning and EDA.
MySQL: For data storage and query execution.
Power BI/Tableau: For interactive visualizations.

Ensure Python 3.x is installed.
Install required Python libraries via requirements.txt:
bash
Copy code
pip install -r requirements.txt
MySQL Setup:

Install MySQL and configure the database.
Import data into MySQL tables by running the data preparation scripts.
Power BI:

Use the .pbix Power BI file to view the pre-built dashboards.
Ensure data connections to MySQL are correctly configured for live data refresh.
Project Structure
data_cleaning.py: Cleans and prepares raw data for analysis.
sql_queries.py: Executes SQL queries to extract insights from the MySQL database.
dashboard_creation.pbix: Power BI file containing the interactive dashboards.
requirements.txt: List of all dependencies required for Python environment setup.
Usage
Clone the repository:

bash
Copy code
git clone https://github.com/your-repository.git
Run data cleaning and SQL execution scripts:

bash
Copy code
python data_cleaning.py
python sql_queries.py
Open the Power BI file for dashboard interaction and exploration:

Ensure data refresh is set to live query mode.
Contributions
Contributions are welcome. Feel free to open a pull request or submit an issue on GitHub to suggest improvements or additional features.

Demo
Watch a demo video showcasing the Power BI dashboards: Demo Video
